{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "import random\n",
    "import numpy as np\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn import svm\n",
    "from sklearn.experimental import enable_iterative_imputer\n",
    "from sklearn.impute import IterativeImputer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(569, 31)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_original = pd.read_csv('breast_cancer_data.csv')\n",
    "data_original = data_original.drop('Unnamed: 32', axis = 1)\n",
    "data_original = data_original.drop('id', axis = 1)\n",
    "#shuffling the dataframe\n",
    "data_original = data_original.sample(frac=1)\n",
    "data_original.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = data_original['diagnosis']\n",
    "Y = [1.0 if ele == \"M\" else 0.0 for ele in labels] #convert labels M and B to binary(1 and 0)\n",
    "data_original = data_original.drop('diagnosis', axis=1)\n",
    "X = data_original\n",
    "#Create test dataset\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size = 0.2)\n",
    "\n",
    "X_train['diagnosis'] = Y_train\n",
    "train_original = X_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(455, 31)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_original.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_data_with_missing_values(data, portion_to_remove):\n",
    "    ix = [(row, col) for row in range(data.shape[0]) for col in range(data.shape[1])]\n",
    "    for row, col in random.sample(ix, int(round(portion*len(ix)))):\n",
    "        data.iat[row, col] = np.nan\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_missing_data_row(data):\n",
    "    df = data.copy()\n",
    "    df = df.dropna()\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def impute_missing_data(data):\n",
    "    #we generate labels, denoted by Y (diagnosis column) and the rest of the data will be denoted by X\n",
    "    Y = data['diagnosis']\n",
    "    data = data.drop('diagnosis', axis=1)#drop the diagnosis column from the dataframe\n",
    "    imp = IterativeImputer(max_iter=10, random_state=0)\n",
    "    imp.fit(data)  \n",
    "    X_transformed = imp.transform(data)\n",
    "    imputed_data = pd.DataFrame(X_transformed, columns= list(data))\n",
    "    imputed_data['diagnosis'] = Y\n",
    "    #to remove rows with unknown labels\n",
    "    imputed_data = remove_missing_data_row(imputed_data)\n",
    "    return imputed_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "portions = [0.02, 0.05]\n",
    "missing_data = {}\n",
    "\n",
    "for portion in portions:\n",
    "    temp = train_original.copy()\n",
    "    missing_data[portion] = get_data_with_missing_values(temp, portion)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "removed_data = {}\n",
    "imputed_data = {}\n",
    "\n",
    "for portion in portions:\n",
    "    removed_data[portion] = remove_missing_data_row(missing_data[portion])\n",
    "    imputed_data[portion] = impute_missing_data(missing_data[portion])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def logreg(X_train,Y_train):\n",
    "    clf = LogisticRegression().fit(X_train, Y_train)\n",
    "    Y_predicted = clf.predict(X_test)\n",
    "    score = f1_score(Y_test, Y_predicted)\n",
    "    return score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def decisiontree(X_train, Y_train):\n",
    "    clf = DecisionTreeClassifier(criterion=\"gini\").fit(X_train, Y_train)\n",
    "    Y_predicted = clf.predict(X_test)\n",
    "    score = f1_score(Y_test, Y_predicted)\n",
    "    return score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def randomforest(X_train, Y_train):\n",
    "    clf = RandomForestClassifier().fit(X_train, Y_train)\n",
    "    Y_predicted = clf.predict(X_test)\n",
    "    score = f1_score(Y_test, Y_predicted)\n",
    "    return score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mysvm(X_train, Y_train):\n",
    "    clf = svm.SVC().fit(X_train, Y_train)\n",
    "    Y_predicted = clf.predict(X_test)\n",
    "    score = f1_score(Y_test, Y_predicted)\n",
    "    return score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_score_from_data(df, method):\n",
    "    #we generate labels, denoted by Y (diagnosis column) and the rest of the data will be denoted by X\n",
    "    Y_train = df['diagnosis']\n",
    "    df = df.drop('diagnosis', axis=1)#drop the diagnosis column from the dataframe\n",
    "    df = df.drop('missing',axis=1)\n",
    "    X_train = df\n",
    "    \n",
    "    \n",
    "    if method==\"logreg\":\n",
    "        score = logreg(X_train, Y_train)\n",
    "    elif method==\"decisiontree\":\n",
    "        score = decisiontree(X_train, Y_train)\n",
    "    elif method==\"randomforest\":\n",
    "        score = randomforest(X_train, Y_train)\n",
    "    elif method==\"svm\":\n",
    "        score = mysvm(X_train, Y_train)\n",
    "    return score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_new_score(data, replacement_parameter):\n",
    "    if replacement_parameter == \"remove_missing\":\n",
    "        temp_df = remove_missing_data_row(data)\n",
    "    elif replacement_parameter == \"inpute\":\n",
    "        temp_df = impute_missing_data(data)\n",
    "    new_score = get_score_from_data(temp_df, method)\n",
    "    return new_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def shuffle_missing_labels(data):\n",
    "    new_df = data.copy()\n",
    "    new_df['missing'] = np.random.permutation(new_df['missing'].values)\n",
    "    return new_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def significance_test_missing_data(portion, replacement_parameter, method):\n",
    "\n",
    "    portion1 = 0.0\n",
    "    portion2 = portion\n",
    "    \n",
    "    \n",
    "    if replacement_parameter == \"remove_missing\":\n",
    "        data_with_missing_values = removed_data[portion]\n",
    "    elif replacement_parameter == \"impute\":\n",
    "        data_with_missing_values = imputed_data[portion]\n",
    "    \n",
    "    data_with_missing_values[\"missing\"] = [portion]*len(data_with_missing_values.index)\n",
    "    \n",
    "    data_orig = train_original.copy() #TODO\n",
    "    data_orig[\"missing\"] = [0.0]*len(data_orig.index)\n",
    "\n",
    "    \n",
    "    score_missing_data = get_score_from_data(data_with_missing_values, method)\n",
    "    orig_score = get_score_from_data(data_orig, method)\n",
    "    observed_score_diff =  score_missing_data - orig_score\n",
    "    \n",
    "    data = pd.concat([data_orig,data_with_missing_values])\n",
    "        \n",
    "    count = 0\n",
    "    num_shuffles = 1000\n",
    "        \n",
    "    for i in range(num_shuffles):\n",
    "#         if(i!=0 and i%20 ==0):\n",
    "#             print(\"Done: \", i)\n",
    "        new_df = shuffle_missing_labels(data)\n",
    "    \n",
    "        new_df_portion_1 = new_df[:][new_df.missing == portion1]\n",
    "        new_df_portion_2 = new_df[:][new_df.missing == portion2]\n",
    "\n",
    "        \n",
    "        score_diff = get_score_from_data(new_df_portion_1, method) - get_score_from_data(new_df_portion_2, method)\n",
    "        \n",
    "        if observed_score_diff < 0 and score_diff <= observed_score_diff:\n",
    "            count += 1\n",
    "        elif observed_score_diff >= 0 and score_diff >= observed_score_diff:\n",
    "            count += 1\n",
    "    ######################################\n",
    "    #\n",
    "    # Output\n",
    "    #\n",
    "    ######################################\n",
    "    print(\"**********Removing \", portion*100, \"% of data****************\")\n",
    "    \n",
    "    print(\"Score on original: \", orig_score)\n",
    "    print(\"Score on Missing data: \", score_missing_data)\n",
    "    print (\"Observed difference of two scores: %.2f\" % observed_score_diff)\n",
    "    print (count, \"out of\", num_shuffles, \"experiments had a difference of two scores\", end=\" \")\n",
    "    if observed_score_diff < 0:\n",
    "        print (\"less than or equal to\", end=\" \")\n",
    "    else:\n",
    "        print (\"greater than or equal to\", end=\" \")\n",
    "    print (\"%.2f\" % observed_score_diff, \".\")\n",
    "    print (\"The chance of getting a difference of two scores\", end=\" \")\n",
    "    if observed_score_diff < 0:\n",
    "        print (\"less than or equal to\", end=\" \")\n",
    "    else:\n",
    "        print (\"greater than or equal to\", end=\" \")\n",
    "    print (\"%.2f\" % observed_score_diff, \"is %.4f\"%(count / float(num_shuffles)), \"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Approach 1: Remove missing data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "**********Removing  2.0 % of data****************\n",
      "Score on original:  0.9500000000000001\n",
      "Score on Missing data:  0.9500000000000001\n",
      "Observed difference of two scores: 0.00\n",
      "721 out of 1000 experiments had a difference of two scores greater than or equal to 0.00 .\n",
      "The chance of getting a difference of two scores greater than or equal to 0.00 is 0.7210 \n",
      "\n",
      "**********Removing  5.0 % of data****************\n",
      "Score on original:  0.9500000000000001\n",
      "Score on Missing data:  0.8947368421052632\n",
      "Observed difference of two scores: -0.06\n",
      "0 out of 1000 experiments had a difference of two scores less than or equal to -0.06 .\n",
      "The chance of getting a difference of two scores less than or equal to -0.06 is 0.0000 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "for portion in portions:\n",
    "    significance_test_missing_data(portion, \"remove_missing\", \"logreg\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "**********Removing  2.0 % of data****************\n",
      "Score on original:  0.926829268292683\n",
      "Score on Missing data:  0.9024390243902439\n",
      "Observed difference of two scores: -0.02\n",
      "249 out of 1000 experiments had a difference of two scores less than or equal to -0.02 .\n",
      "The chance of getting a difference of two scores less than or equal to -0.02 is 0.2490 \n",
      "\n",
      "**********Removing  5.0 % of data****************\n",
      "Score on original:  0.9069767441860465\n",
      "Score on Missing data:  0.8433734939759037\n",
      "Observed difference of two scores: -0.06\n",
      "40 out of 1000 experiments had a difference of two scores less than or equal to -0.06 .\n",
      "The chance of getting a difference of two scores less than or equal to -0.06 is 0.0400 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "for portion in portions:\n",
    "    significance_test_missing_data(portion, \"remove_missing\", \"decisiontree\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "**********Removing  2.0 % of data****************\n",
      "Score on original:  0.975\n",
      "Score on Missing data:  0.9210526315789475\n",
      "Observed difference of two scores: -0.05\n",
      "30 out of 1000 experiments had a difference of two scores less than or equal to -0.05 .\n",
      "The chance of getting a difference of two scores less than or equal to -0.05 is 0.0300 \n",
      "\n",
      "**********Removing  5.0 % of data****************\n",
      "Score on original:  0.9487179487179488\n",
      "Score on Missing data:  0.8493150684931506\n",
      "Observed difference of two scores: -0.10\n",
      "0 out of 1000 experiments had a difference of two scores less than or equal to -0.10 .\n",
      "The chance of getting a difference of two scores less than or equal to -0.10 is 0.0000 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "for portion in portions:\n",
    "    significance_test_missing_data(portion, \"remove_missing\", \"randomforest\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "**********Removing  2.0 % of data****************\n",
      "Score on original:  0.0\n",
      "Score on Missing data:  0.0\n",
      "Observed difference of two scores: 0.00\n",
      "1000 out of 1000 experiments had a difference of two scores greater than or equal to 0.00 .\n",
      "The chance of getting a difference of two scores greater than or equal to 0.00 is 1.0000 \n",
      "\n",
      "**********Removing  5.0 % of data****************\n",
      "Score on original:  0.0\n",
      "Score on Missing data:  0.0\n",
      "Observed difference of two scores: 0.00\n",
      "993 out of 1000 experiments had a difference of two scores greater than or equal to 0.00 .\n",
      "The chance of getting a difference of two scores greater than or equal to 0.00 is 0.9930 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "for portion in portions:\n",
    "    significance_test_missing_data(portion, \"remove_missing\", \"svm\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Approach 2: Imputation of multivariate missing data using sklearn's impute method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "**********Removing  2.0 % of data****************\n",
      "Score on original:  0.9500000000000001\n",
      "Score on Missing data:  0.1276595744680851\n",
      "Observed difference of two scores: -0.82\n",
      "0 out of 1000 experiments had a difference of two scores less than or equal to -0.82 .\n",
      "The chance of getting a difference of two scores less than or equal to -0.82 is 0.0000 \n",
      "\n",
      "**********Removing  5.0 % of data****************\n",
      "Score on original:  0.9500000000000001\n",
      "Score on Missing data:  0.125\n",
      "Observed difference of two scores: -0.83\n",
      "0 out of 1000 experiments had a difference of two scores less than or equal to -0.83 .\n",
      "The chance of getting a difference of two scores less than or equal to -0.83 is 0.0000 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "for portion in portions:\n",
    "    significance_test_missing_data(portion, \"impute\", \"logreg\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "**********Removing  2.0 % of data****************\n",
      "Score on original:  0.9024390243902439\n",
      "Score on Missing data:  0.45\n",
      "Observed difference of two scores: -0.45\n",
      "0 out of 1000 experiments had a difference of two scores less than or equal to -0.45 .\n",
      "The chance of getting a difference of two scores less than or equal to -0.45 is 0.0000 \n",
      "\n",
      "**********Removing  5.0 % of data****************\n",
      "Score on original:  0.9156626506024096\n",
      "Score on Missing data:  0.3181818181818182\n",
      "Observed difference of two scores: -0.60\n",
      "0 out of 1000 experiments had a difference of two scores less than or equal to -0.60 .\n",
      "The chance of getting a difference of two scores less than or equal to -0.60 is 0.0000 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "for portion in portions:\n",
    "    significance_test_missing_data(portion, \"impute\", \"decisiontree\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "**********Removing  2.0 % of data****************\n",
      "Score on original:  0.975\n",
      "Score on Missing data:  0.14492753623188406\n",
      "Observed difference of two scores: -0.83\n",
      "0 out of 1000 experiments had a difference of two scores less than or equal to -0.83 .\n",
      "The chance of getting a difference of two scores less than or equal to -0.83 is 0.0000 \n",
      "\n",
      "**********Removing  5.0 % of data****************\n",
      "Score on original:  0.975\n",
      "Score on Missing data:  0.31746031746031744\n",
      "Observed difference of two scores: -0.66\n",
      "0 out of 1000 experiments had a difference of two scores less than or equal to -0.66 .\n",
      "The chance of getting a difference of two scores less than or equal to -0.66 is 0.0000 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "for portion in portions:\n",
    "    significance_test_missing_data(portion, \"impute\", \"randomforest\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "**********Removing  2.0 % of data****************\n",
      "Score on original:  0.0\n",
      "Score on Missing data:  0.0\n",
      "Observed difference of two scores: 0.00\n",
      "1000 out of 1000 experiments had a difference of two scores greater than or equal to 0.00 .\n",
      "The chance of getting a difference of two scores greater than or equal to 0.00 is 1.0000 \n",
      "\n",
      "**********Removing  5.0 % of data****************\n",
      "Score on original:  0.0\n",
      "Score on Missing data:  0.0\n",
      "Observed difference of two scores: 0.00\n",
      "1000 out of 1000 experiments had a difference of two scores greater than or equal to 0.00 .\n",
      "The chance of getting a difference of two scores greater than or equal to 0.00 is 1.0000 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "for portion in portions:\n",
    "    significance_test_missing_data(portion, \"impute\", \"svm\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
